{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28.04.25, © Dmytro Sokhin KI-21-1, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://github.com/https-deeplearning-ai/tensorflow-1-public"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2s0EJ5Fy4u2"
   },
   "source": [
    "# Workshop 1 Assignment 2: Implementing Callbacks in TensorFlow using the MNIST Dataset\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy and stops once this threshold is achieved. In the lecture you saw how this was done for the loss but here you will be using accuracy instead.\n",
    "\n",
    "Some notes:\n",
    "1. Your network should succeed in less than 9 epochs.\n",
    "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\" and stop training.\n",
    "3. If you add any additional variables, make sure you use the same names as the ones used in the class. This is important for the function signatures (the parameters and names) of the callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect the data\n",
    "\n",
    "Begin by loading the data. A couple of things to notice:\n",
    "\n",
    "- The file `mnist.npz` is already included in the current workspace under the `data` directory. By default the `load_data` from Keras accepts a path relative to `~/.keras/datasets` but in this case it is stored somewhere else, as a result of this, you need to specify the full path.\n",
    "\n",
    "- `load_data` returns the train and test sets in the form of the tuples `(x_train, y_train), (x_test, y_test)` but in this exercise you will be needing only the train set so you can ignore the second tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\user\\Downloads\n",
      "Attempting to load data from: c:\\Users\\user\\Downloads\\Workshop\\data\\mnist.npz\n",
      "Data loaded successfully using np.load().\n",
      "x_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "Data normalization complete.\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "print(f\"Current Working Directory: {current_dir}\")\n",
    "\n",
    "data_dir = os.path.join(current_dir, \"Workshop\", \"data\") \n",
    "data_path = os.path.join(data_dir, \"mnist.npz\") \n",
    "print(f\"Attempting to load data from: {data_path}\") \n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    with np.load(data_path) as data:\n",
    "        x_train = data['x_train']\n",
    "        y_train = data['y_train']\n",
    "    print(\"Data loaded successfully using np.load().\")\n",
    "    print(\"x_train shape:\", x_train.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "else:\n",
    "    print(f\"Error: File not found at {data_path}\")\n",
    "    x_train, y_train = None, None \n",
    "\n",
    "if x_train is not None:\n",
    "    x_train = x_train / 255.0\n",
    "    print(\"Data normalization complete.\")\n",
    "else:\n",
    "    print(\"Skipping normalization because data was not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look at the shape of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 examples with shape (28, 28)\n"
     ]
    }
   ],
   "source": [
    "data_shape = x_train.shape\n",
    "\n",
    "print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining your callback\n",
    "\n",
    "Now it is time to create your own custom callback. For this complete the `myCallback` class and the `on_epoch_end` method in the cell below. If you need some guidance on how to proceed, check out this [link](https://www.tensorflow.org/guide/keras/custom_callback)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GRADED CLASS: myCallback\n",
    "### START CODE HERE\n",
    "\n",
    "# Remember to inherit from the correct class -> tf.keras.callbacks.Callback\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "        # Define the correct function signature for on_epoch_end\n",
    "        # Вона приймає 'self', 'epoch' (номер епохи), і 'logs' (словник з метриками)\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            # Перевіряємо, чи існує ключ 'accuracy' у словнику logs\n",
    "            # та чи його значення більше 0.99\n",
    "            if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99:\n",
    "                print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "\n",
    "                # Stop training once the above condition is met\n",
    "                # Встановлюємо атрибут моделі stop_training в True\n",
    "                self.model.stop_training = True\n",
    "\n",
    "### END CODE HERE\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train your model\n",
    "\n",
    "Now that you have defined your callback it is time to complete the `train_mnist` function below. \n",
    "\n",
    "**You must set your model to train for 10 epochs and the callback should fire before the 9th epoch for you to pass this assignment.**\n",
    "\n",
    "**Hint:**\n",
    "- Feel free to try the architecture for the neural network that you see fit but in case you need extra help you can check out an architecture that works pretty well at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEHcB3kqyHZ6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_mnist\n",
    "def train_mnist(x_train, y_train):\n",
    "\n",
    "    ### START CODE HERE\n",
    "\n",
    "    # Instantiate the callback class\n",
    "    callbacks = myCallback() # Створюємо екземпляр нашого колбека\n",
    "\n",
    "    # Define the model\n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Вхідний шар: випрямляє зображення 28x28 в 1D вектор (784 елементи)\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "\n",
    "        # Прихований шар: повнозв'язний шар з 512 нейронами та ReLU активацією\n",
    "        tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "\n",
    "        # Вихідний шар: повнозв'язний шар з 10 нейронами (по одному для кожного класу 0-9)\n",
    "        # та softmax активацією для отримання ймовірностей класів\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy', # Використовуємо, коли мітки є цілими числами\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model for 10 epochs adding the callbacks\n",
    "    # and save the training history\n",
    "    history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
    "\n",
    "    ### END CODE HERE\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the `train_mnist` passing in the appropiate parameters to get the training history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sFgpwbGly4u4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.8965 - loss: 0.3521\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - accuracy: 0.9750 - loss: 0.0831\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.0523\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.9889 - loss: 0.0346\n",
      "Epoch 5/10\n",
      "\u001b[1m1870/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.0252\n",
      "Reached 99% accuracy so cancelling training!\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.0253\n"
     ]
    }
   ],
   "source": [
    "hist = train_mnist(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see the message `Reached 99% accuracy so cancelling training!` printed out after less than 9 epochs it means your callback worked as expected. "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
